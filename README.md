# CMPT365 Final Project

The first program, "Project(Encode).py", takes the images of the character and turn their backgrounds to black. Then, a short video is chosen by the user. For each frame of the video, we get the size of the character images to place on the video images. Afterwards, we make a mask of the character image and the inverse of the mask. Then, we merge the background and foreground and we get a new image with the character on the video frame. Each frame will have a different character image as that will make the character animate. The merged images are then compressed following H.261 standard. First, we transform the image from RGB to YCbCr. Then we figure out if the frame should be an I-frame or a P-frame. The first frame is of course an I-frame, each multiple of 4 is an I-frame and the rest are P-frames. For the P-frames, we find the motion vectors and the difference between the preceding frame and the current frame. Then, we do a 4:2:0 chroma subsampling. Then, we scan the output motion vectors to make it into 1D arrays and save them into the .mrg file. For the I-frames, as in JPEG, we do a 4:2:0 chroma subsampling followed by a 2D DCT transformation and then a quantization. Then, we scan the output matrix of quantization to make it into 1D array and save it into .mrg file format. The second program, "Project(Decode).py", takes the .mrg file and decode it to play the video with the animated character.
